---
title: "Confidence interval and hypothesis test"
author: "Osvaldo"
categories: ["statistics"]
tags: ["statistical inference", "nhst", "confidence interval", "binomial"]
date: "2016-07-07"
---



<div id="if-all-tests-are-negative-the-positive-rate-is-zero.-and-its-confidence-interval" class="section level2">
<h2>If all tests are negative, the positive rate is zero. And its confidence interval?</h2>
<p>Some time ago a colleague presented me a simple statistics question which, as usual, turned out to be quite interesting and intriguing. They had run 23 tests that were all negative, and they wanted to have a confidence interval for the proportion of positive outcomes. So, to put it in statistical terms, we have <span class="math inline">\(n\)</span> observations that can be <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>. Each observation has a probability <span class="math inline">\(\theta\)</span> of being positive. In formulas</p>
<p><span class="math display">\[
x_i \in \{0, 1\} \quad \forall i = 1, \ldots , n \\
p(x_i=1) = \theta .
\]</span></p>
<p>We know that the number of successes is binomially distributed, thus a sufficient statistics is <span class="math inline">\(T = \sum_i x_i\)</span> and that the maximum likelihood estimator for the binomial proportion is</p>
<p><span class="math display">\[
\hat{\theta} = \frac{T}{n} .
\]</span></p>
<p>If the observations are all negative, the estimate for the rate is clearly zero, but what about its confidence interval? I had never been asked to estimate the confidence interval for the binomial distribution, so I was totally unprepared (shame on me!). Quite instinctively, I computed the probability to observe all 23 results negative for a given <span class="math inline">\(\theta\)</span>, set this to 5% and solved for <span class="math inline">\(\theta\)</span>. Result, 12.2%. In formula</p>
<p><span class="math display">\[
p(\mathrm{all\;negatives}\, |\, \theta) = (1-\theta)^n \leq \alpha,
\]</span></p>
<p>which gives, solving for <span class="math inline">\(\theta\)</span>,</p>
<p><span class="math display">\[
\theta_u = 1 - \alpha^{1/n} \\
\theta_u(n=23) = 12.2\% .
\]</span></p>
<p>In other words, what I did was to compute the highest <span class="math inline">\(\theta\)</span> for which I would be very surprised (5%) to see all negative outcomes. This is equivalent to being quite sure (95% sure) to observe at least one positive outcome.</p>
<p>My colleague had found the formula for the <a href="http://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Clopper-Pearson_interval">Clopper-Pearson interval</a> and applied it to their case: different result. Of course, I thought: I computed the probability to observe data as extreme or more extreme than those observed for a given value of the parameter. I did a hypothesis test, not a confidence interval.</p>
<p>It would have been the end of the story, had I not tried this <a href="http://www.danielsoper.com/statcalc3/calc.aspx?id=85">online calculator</a>. It reports <span class="math inline">\(0 \leq \theta \leq 0.12\)</span> to be the 90% interval for <span class="math inline">\(n=23\)</span>. This was no coincidence, as the plot below shows.</p>
<p>In other words, for any number of tests (at least, between five and thirty) <em>my</em> estimate (violet points) matches the upper limit of the 90% confidence interval computed with the Clopper-Pearson method (magenta line).</p>
<pre class="r"><code>library(ggplot2)
library(ggthemr)
ggthemr(&#39;solarized&#39;, type=&#39;outer&#39;)

# computing 90% confidence interval with &quot;exact&quot; meaning Clopper-Pearson
library(binom)
cis &lt;- binom.confint(0, 5:30, conf.level = 0.9, methods=&quot;exact&quot;)

# max theta for which n all negative outcomes have probability 5%
p_all_neg &lt;- 1-0.05**(1./5:30)

df &lt;- data.frame(x=5:30, y1=cis$upper, y2=p_all_neg)
p &lt;- ggplot(df, aes(x)) +
  geom_line(y = df$y1, show.legend = TRUE, colour=&#39;#d33682&#39;) +
  geom_point(y = df$y2, show.legend = TRUE, colour=&#39;#6c71c4&#39;) +
  xlab(&quot;trials&quot;) +
  ylab(expression(theta)) +
  ylim(0.0, 0.5) +
  theme(axis.title.x = element_text(face=&quot;bold&quot;, size=18),
        axis.text.x  = element_text(angle=0, vjust=0.0, size=14),
        axis.title.y = element_text(face=&quot;bold&quot;, size=18),
        axis.text.y  = element_text(angle=0, vjust=0.0, size=14))
print(p)</code></pre>
<p><img src="/post/2016-07-07-confidence-interval-and-hypothesis-test_files/figure-html/plot-1.png" width="672" /></p>
</div>
<div id="finding-confidence-intervals" class="section level2">
<h2>Finding confidence intervals</h2>
<p>There is a one-to-one correspondence between confidence intervals and hypothesis tests. As a matter of fact, confidence sets are found by inverting a test statistics.</p>
<p>Let’s start revisiting a few concepts, following the <a href="http://books.google.ch/books/about/Statistical_inference.html?id=0x_vAAAAMAAJ&amp;redir_esc=y">classics</a>. We have a hypothesis for a parameter of interest <span class="math inline">\(\theta\)</span>. The hypothesis says that it has a certain value</p>
<p><span class="math display">\[
H_0 : \theta = \theta_0.
\]</span></p>
<p>We have data <span class="math inline">\(X\)</span> and a test statistics telling us whether to reject the hypothesis or not. The acceptance region <span class="math inline">\(A(\theta_0)\)</span> is the region of the sample space for which we do not reject <span class="math inline">\(H_0\)</span> at a level <span class="math inline">\(\alpha\)</span>. In symbols</p>
<p><span class="math display">\[
p(X \in A(\theta_0)) \geq 1 - \alpha
\]</span></p>
<p>or</p>
<p><span class="math display">\[
p(X \notin A(\theta_0)) \leq \alpha.
\]</span></p>
<p>Now, for each realisation of the data <span class="math inline">\(X\)</span>, we take the values of <span class="math inline">\(\theta\)</span> for which the hypothesis <span class="math inline">\(H_0\)</span> is accepted. Then we have built a confidence set for <span class="math inline">\(\theta\)</span>. We define <span class="math inline">\(C(X)\)</span> as the set in parameter</p>
<p><span class="math display">\[
C(X)=\{\theta_0 : x \in A(\theta_0)\}.
\]</span></p>
<p>Then, <span class="math inline">\(C(X)\)</span> is a <span class="math inline">\(1 - \alpha\)</span> confidence set. This follows quite immediately from the definition of acceptance region above</p>
<p><span class="math display">\[
p(\theta \in C(X)) = p(X \in A(\theta_0)) \geq 1 − \alpha.
\]</span></p>
</div>
<div id="clopper-pearson-estimator" class="section level2">
<h2>Clopper-Pearson estimator</h2>
<p>There are several estimators for the confidence interval of the binomial proportion. The advantage of this one is that it is exact, rather than based on the normal approximation (see the Wikipedia page linked above). The disadvantage is that it is conservative, i.e. there might be a smaller interval with the same confidence level. The estimated interval is defined as</p>
<p><span class="math display">\[
\{\theta : p(\mathrm{Bin}(n, \theta) \leq T) &gt; \frac{\alpha}{2} \} \cap
\{\theta : p(\mathrm{Bin}(n, \theta) \geq T) &gt; \frac{\alpha}{2} \}.
\]</span></p>
<p>From this definition we reconcile the fact that my estimate at 95% coincides with the Clopper-Pearson at 90%. In fact, since we are in the special case of <span class="math inline">\(T=0\)</span>, we can write the Clopper-Pearson as</p>
<p><span class="math display">\[
\{\theta : p(\mathrm{Bin}(n, \theta) \leq 0) &gt; \frac{\alpha}{2} \} \cap
\{\theta : p(\mathrm{Bin}(n, \theta) \geq 0) &gt; \frac{\alpha}{2} \} =
\{\theta : p(\mathrm{Bin}(n, \theta) = 0) &gt; \frac{\alpha}{2} \}.
\]</span></p>
<p>By taking <span class="math inline">\(\alpha = 0.10\)</span> in the Clopper-Pearson estimate, we have the formula I used for my estimate.</p>
</div>
<div id="a-final-observation" class="section level2">
<h2>A final observation</h2>
<p>What is most interesting to my colleague? The hypothesis test says that those data would already exclude <span class="math inline">\(\theta=0.12\)</span> or higher at 5%, but the 95% interval according to Clopper-Pearson is <span class="math inline">\(0 \leq \theta \leq 0.15\)</span>. As we saw they are two different but intimately related things. What is more important to you depends largely on your taste. We also had the chance to underline something that is often neglected: finding an <span class="math inline">\(\alpha\)</span> confidence interval doesn’t mean we found the smallest interval that contains the true value with probability <span class="math inline">\(1 - \alpha\)</span>. If you want to investigate an extreme consequence of this, you can visit <a href="http://www.roma1.infn.it/~dagos/ci_calc.html">the ultimate confidence intervals calculator</a>.</p>
<p><em>Header image from <a href="https://flic.kr/p/9u9wZk">Flickr</a></em></p>
</div>
